seed: 42
log_level: info
output_dir: ./benchmark_output/
write_json_trace: true
write_chrome_trace: true
write_metrics: true
enable_profiling: false
gpu_memory_utilization: 0.9
time_limit: 1800 # seconds
replica_resource_mapping: ""

cluster:
  num_replicas: 1

model:
  name: meta-llama/Meta-Llama-3-8B
  # name: meta-llama/Llama-2-7b-hf
  # name: 01-ai/Yi-34B-200K
  # name: codellama/CodeLlama-34b-Instruct-hf
  # name: Qwen/Qwen-72B
  # name: tiiuae/falcon-180B
  tensor_parallel_degree: 4
  pipeline_parallel_degree: 1
  max_model_len: 4096
  load_format: dummy
  attention_backend: flash_attention

request_generator:
  provider: synthetic

synthetic_request_generator:
  length_provider: trace
  interval_provider: poisson
  num_requests: 64

trace_request_generator:
  trace_file: ./data/processed_traces/sydney_enterprise.csv
  date: '2023-08-21'
  prefill_scale_factor: 0.3
  decode_scale_factor:  1
  time_scale_factor: 0.04
  max_tokens: 4096

# Config for synthetic trace generator
trace_request_length_generator:
  trace_file: ./data/processed_traces/sharegpt_8k_filtered_stats_llama2_tokenizer.csv
  # trace_file: ./data/processed_traces/arxiv_summarization_filtered_stats_llama2_tokenizer.csv
  prefill_scale_factor: 1
  decode_scale_factor:  1
  max_tokens: 4096

trace_request_interval_generator:
  trace_file: ./data/processed_traces/AzureFunctionsInvocationTraceForTwoWeeksJan2021Processed.csv
  start_time: "1970-01-04 12:00:00"
  end_time: "1970-01-04 15:00:00"
  time_scale_factor: 0.3

poisson_request_interval_generator:
  qps: 1.0

gamma_request_interval_generator:
  cv: 0.5
  qps: 0.2

zipf_request_length_generator:
  theta: 0.6
  scramble: false
  min_tokens: 1024
  max_tokens: 4096
  prefill_to_decode_ratio: 20.0

uniform_request_length_generator:
  min_tokens: 1024
  max_tokens: 4096
  prefill_to_decode_ratio: 20.0

fixed_request_length_generator:
  prefill_tokens: 4096
  decode_tokens: 512

replica_scheduler:
  provider: sarathi
  max_batch_size: 128

sarathi_scheduler:
  chunk_size: 512
  enable_dynamic_chunking_schedule: false
  # next four params apply only when using dynamic schedule
  low_chunk_size: 128
  high_chunk_size: 2048
  # chunk_schedule_max_tokens: 4096
  chunk_schedule_max_tokens: 131072
  chunk_schedule_stages: 16

vllm_scheduler:
  max_tokens_in_batch: null

simple_chunking_scheduler:
  chunk_size: 512

metrics_store:
  wandb_project: ""
  wandb_sweep_id: ""
  wandb_run_id: ""
  wandb_group: ""
  wandb_run_name: ""
  enable_op_level_metrics: false
  enable_cpu_op_level_metrics: false
  enable_request_outputs: false
  keep_individual_batch_metrics: false
