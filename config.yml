model: meta-llama/Llama-2-7b-hf
replica_id: 0
replica_resource_mapping: []
tokenizer: meta-llama/Llama-2-7b-hf
tokenizer_mode: auto
trust_remote_code: true
download_dir: null
load_format: auto
dtype: auto
seed: 0
pipeline_parallel_size: 1
tensor_parallel_size: 8
block_size: 16
gpu_memory_utilization: 0.85
revision: null
scheduler_type: sarathi
max_model_len: 4096
max_num_seqs: 128
max_num_batched_tokens: null
chunk_size: 100
enable_dynamic_chunking_schedule: false
low_chunk_size: null
high_chunk_size: null
chunk_schedule_max_tokens: null
chunk_schedule_stages: null
write_metrics: true
output_dir: .
wandb_project: null
wandb_sweep_id: null
wandb_run_id: null
wandb_group: null
wandb_run_name: null
enable_op_level_metrics: false
enable_cpu_op_level_metrics: false
enable_chrome_trace: false
enable_request_outputs: false
keep_individual_batch_metrics: false
attention_backend: FLASHINFER_UNPAGED
