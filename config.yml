model: meta-llama/Llama-2-70b-hf
replica_id: 0
tokenizer: meta-llama/Llama-2-70b-hf
tokenizer_mode: auto
trust_remote_code: false
download_dir: null
load_format: auto
dtype: float16
seed: 0
worker_use_ray: false
pipeline_parallel_size: 1
tensor_parallel_size: 8
block_size: 16
swap_space: 4
gpu_memory_utilization: 0.9
disable_log_stats: true
revision: null
quantization: null
scheduler_type: vllm
max_model_len: null
max_num_seqs: 64
max_num_batched_tokens: 4096
chunk_size: null
enable_rolling_prefills: true
prefill_fitting_tolerance: 0.2
write_metrics: true
output_dir: .
subsamples: 1000
save_table_to_wandb: false
wandb_project: null
wandb_group: null
wandb_run_name: null
enable_op_level_metrics: false
enable_chrome_trace: false
enable_request_outputs: false
enable_cpu_op_level_metrics: true
enable_high_level_cuda_metrics: false
